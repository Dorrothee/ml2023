{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Лабораторна робота №7\n",
    "### Студентки групи МІТ-31 (підгрупа 1)\n",
    "### Борук Дарини Ігорівни"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1800 images belonging to 3 classes.\n",
      "Found 450 images belonging to 3 classes.\n",
      "Found 750 images belonging to 3 classes.\n",
      "Epoch 1/5\n",
      "57/57 [==============================] - 84s 1s/step - loss: 4.2820 - accuracy: 0.4589 - val_loss: 0.9185 - val_accuracy: 0.5822\n",
      "Epoch 2/5\n",
      "57/57 [==============================] - 83s 1s/step - loss: 0.8579 - accuracy: 0.6167 - val_loss: 0.8493 - val_accuracy: 0.6178\n",
      "Epoch 3/5\n",
      "57/57 [==============================] - 90s 2s/step - loss: 0.8043 - accuracy: 0.6467 - val_loss: 0.8434 - val_accuracy: 0.6422\n",
      "Epoch 4/5\n",
      "57/57 [==============================] - 97s 2s/step - loss: 0.7807 - accuracy: 0.6589 - val_loss: 0.8319 - val_accuracy: 0.6267\n",
      "Epoch 5/5\n",
      "57/57 [==============================] - 102s 2s/step - loss: 0.7510 - accuracy: 0.6733 - val_loss: 0.8729 - val_accuracy: 0.6333\n",
      "24/24 [==============================] - 13s 549ms/step - loss: 0.8588 - accuracy: 0.6267\n",
      "model_1 - Test Accuracy: 0.6266666650772095, Training Time: 264.4629912376404 seconds\n",
      "Epoch 1/5\n",
      "57/57 [==============================] - 106s 2s/step - loss: 1.0958 - accuracy: 0.4711 - val_loss: 0.8870 - val_accuracy: 0.6089\n",
      "Epoch 2/5\n",
      "57/57 [==============================] - 105s 2s/step - loss: 0.8203 - accuracy: 0.6183 - val_loss: 0.8379 - val_accuracy: 0.5956\n",
      "Epoch 3/5\n",
      "57/57 [==============================] - 86s 2s/step - loss: 0.7566 - accuracy: 0.6767 - val_loss: 0.7524 - val_accuracy: 0.6822\n",
      "Epoch 4/5\n",
      "57/57 [==============================] - 79s 1s/step - loss: 0.7066 - accuracy: 0.6989 - val_loss: 0.7171 - val_accuracy: 0.6956\n",
      "Epoch 5/5\n",
      "57/57 [==============================] - 83s 1s/step - loss: 0.6681 - accuracy: 0.7178 - val_loss: 0.8554 - val_accuracy: 0.6089\n",
      "24/24 [==============================] - 5s 216ms/step - loss: 0.8525 - accuracy: 0.6333\n",
      "model_2 - Test Accuracy: 0.6333333253860474, Training Time: 225.9375138282776 seconds\n",
      "Epoch 1/5\n",
      "57/57 [==============================] - 252s 4s/step - loss: 1.0983 - accuracy: 0.3894 - val_loss: 1.0968 - val_accuracy: 0.3400\n",
      "Epoch 2/5\n",
      "57/57 [==============================] - 247s 4s/step - loss: 0.9983 - accuracy: 0.4806 - val_loss: 0.9484 - val_accuracy: 0.5178\n",
      "Epoch 3/5\n",
      "57/57 [==============================] - 251s 4s/step - loss: 0.8826 - accuracy: 0.5750 - val_loss: 0.8709 - val_accuracy: 0.6311\n",
      "Epoch 4/5\n",
      "57/57 [==============================] - 239s 4s/step - loss: 0.8837 - accuracy: 0.5839 - val_loss: 0.8677 - val_accuracy: 0.5867\n",
      "Epoch 5/5\n",
      "57/57 [==============================] - 247s 4s/step - loss: 0.8584 - accuracy: 0.6122 - val_loss: 0.8074 - val_accuracy: 0.6489\n",
      "24/24 [==============================] - 15s 628ms/step - loss: 0.7826 - accuracy: 0.6493\n",
      "model_3 - Test Accuracy: 0.6493333578109741, Training Time: 482.8053123950958 seconds\n",
      "Epoch 1/5\n",
      "57/57 [==============================] - 152s 2s/step - loss: 1.0811 - accuracy: 0.5350 - val_loss: 1.0684 - val_accuracy: 0.6889\n",
      "Epoch 2/5\n",
      "57/57 [==============================] - 134s 2s/step - loss: 1.0575 - accuracy: 0.7339 - val_loss: 1.0464 - val_accuracy: 0.7489\n",
      "Epoch 3/5\n",
      "57/57 [==============================] - 142s 2s/step - loss: 1.0350 - accuracy: 0.7356 - val_loss: 1.0243 - val_accuracy: 0.7467\n",
      "Epoch 4/5\n",
      "57/57 [==============================] - 139s 2s/step - loss: 1.0125 - accuracy: 0.7483 - val_loss: 1.0065 - val_accuracy: 0.7444\n",
      "Epoch 5/5\n",
      "57/57 [==============================] - 136s 2s/step - loss: 0.9918 - accuracy: 0.7483 - val_loss: 0.9855 - val_accuracy: 0.7578\n",
      "24/24 [==============================] - 44s 2s/step - loss: 0.9741 - accuracy: 0.7667\n",
      "efficientNet model - Test Accuracy: 0.7666666507720947, Training Time: 714.0730278491974 seconds\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "#Set the seed\n",
    "seed_value = 33\n",
    "tf.random.set_seed(seed_value)\n",
    "\n",
    "# Set image dimensions\n",
    "img_size = (224, 224)\n",
    "batch_size = 32\n",
    "\n",
    "#Define training and test directory paths\n",
    "train_dir = \"C:/university/3year/intelan/zip_food/extracted/10_food_classes_all_data/train/\"\n",
    "test_dir = \"C:/university/3year/intelan/zip_food/extracted/10_food_classes_all_data/test/\"\n",
    "\n",
    "#Assigning our three classes\n",
    "our_classes=['grilled_salmon', 'ramen', 'chicken_wings']\n",
    "\n",
    "#Create train and test data generators and preprocess the data (normalization/scaling)\n",
    "train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "#Import data from directories and turn it into batches\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    validation_split=0.2  #20% of the data will be used for validation\n",
    ")\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1/255.)\n",
    "\n",
    "#Create data generators\n",
    "train_data = train_datagen.flow_from_directory(train_dir,\n",
    "                                               target_size=img_size,\n",
    "                                               batch_size=batch_size,\n",
    "                                               class_mode='categorical',\n",
    "                                               subset='training',  #Specify 'training' for the training set\n",
    "                                               classes=our_classes)\n",
    "\n",
    "val_data = train_datagen.flow_from_directory(train_dir,\n",
    "                                             target_size=img_size,\n",
    "                                             batch_size=batch_size,\n",
    "                                             class_mode='categorical',\n",
    "                                             subset='validation',  #Specify 'validation' for the validation set\n",
    "                                             classes=our_classes)\n",
    "\n",
    "test_data = test_datagen.flow_from_directory(test_dir,\n",
    "                                            target_size=img_size,\n",
    "                                            batch_size=batch_size,\n",
    "                                            class_mode='categorical',\n",
    "                                            classes=our_classes)\n",
    "\n",
    "#Define and train three different deep learning models\n",
    "model_1 = tf.keras.models.Sequential([\n",
    "        tf.keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(224, 224, 3)),\n",
    "        tf.keras.layers.MaxPooling2D(2, 2),\n",
    "        tf.keras.layers.Flatten(),\n",
    "        tf.keras.layers.Dense(128, activation='relu'),\n",
    "        tf.keras.layers.Dense(3, activation='softmax')\n",
    "])\n",
    "model_1.compile(loss=\"categorical_crossentropy\",\n",
    "              optimizer=tf.keras.optimizers.Adam(),\n",
    "              metrics=[\"accuracy\"])\n",
    "\n",
    "\n",
    "model_2 = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Conv2D(16, (3, 3), activation='relu', input_shape=(224, 224, 3)),\n",
    "    tf.keras.layers.MaxPooling2D(2, 2),\n",
    "    tf.keras.layers.Conv2D(32, (3, 3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2, 2),\n",
    "    tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2, 2),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dense(3, activation='softmax')\n",
    "])\n",
    "model_2.compile(loss=\"categorical_crossentropy\",\n",
    "              optimizer=tf.keras.optimizers.Adam(),\n",
    "              metrics=[\"accuracy\"])\n",
    "\n",
    "\n",
    "model_3 = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Conv2D(16, (3, 3), activation='relu', input_shape=(224, 224, 3)),\n",
    "        tf.keras.layers.Conv2D(16, (3, 3), activation='relu'),\n",
    "        tf.keras.layers.MaxPooling2D(2, 2),\n",
    "\n",
    "        tf.keras.layers.Conv2D(32, (3, 3), activation='relu'),\n",
    "        tf.keras.layers.Conv2D(32, (3, 3), activation='relu'),\n",
    "        tf.keras.layers.MaxPooling2D(2, 2),\n",
    "\n",
    "        tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "        tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "        tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "        tf.keras.layers.MaxPooling2D(2, 2),\n",
    "\n",
    "        tf.keras.layers.Flatten(),\n",
    "        tf.keras.layers.Dense(128, activation='relu'),\n",
    "        tf.keras.layers.Dropout(0.5),\n",
    "        tf.keras.layers.Dense(3, activation='softmax')\n",
    "])\n",
    "model_3.compile(loss=\"categorical_crossentropy\",\n",
    "              optimizer=tf.keras.optimizers.Adam(),\n",
    "              metrics=[\"accuracy\"])\n",
    "\n",
    "import tensorflow_hub as hub\n",
    "import time\n",
    "#EfficientNet with TensorFlow Hub\n",
    "url_efficientnet = \"https://tfhub.dev/tensorflow/efficientnet/b3/classification/1\"\n",
    "model_efficientnet = tf.keras.Sequential([\n",
    "    hub.KerasLayer(url_efficientnet, trainable=False),\n",
    "    tf.keras.layers.Dense(3, activation='softmax')\n",
    "])\n",
    "model_efficientnet.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "#Train each model\n",
    "def evaluate_model(model, train_data, test_data):\n",
    "    start_time = time.time()\n",
    "    model.fit(train_data, epochs=5, validation_data=val_data)\n",
    "    end_time = time.time()\n",
    "    test_loss, test_accuracy = model.evaluate(test_data)\n",
    "    evaluation_time = end_time - start_time\n",
    "    return test_accuracy, evaluation_time\n",
    "\n",
    "# Evaluate each model on the test set\n",
    "accuracy_model_1, time_model_1 = evaluate_model(model_1, train_data, test_data)\n",
    "print(f\"model_1 - Test Accuracy: {accuracy_model_1}, Training Time: {training_time_model_1} seconds\")\n",
    "\n",
    "accuracy_model_2, time_model_2 = evaluate_model(model_2, train_data, test_data)\n",
    "print(f\"model_2 - Test Accuracy: {accuracy_model_2}, Training Time: {training_time_model_2} seconds\")\n",
    "\n",
    "accuracy_model_3, time_model_3 = evaluate_model(model_3, train_data, test_data)\n",
    "print(f\"model_3 - Test Accuracy: {accuracy_model_3}, Training Time: {training_time_model_3} seconds\")\n",
    "\n",
    "accuracy_efficientnet, time_efficientnet = evaluate_model(model_efficientnet, train_data, test_data)\n",
    "print(f\"efficientNet model - Test Accuracy: {accuracy_efficientnet}, Training Time: {training_time_efficientnet} seconds\")\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "juppyenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
